# A10

Aula 3202: martes 15:00 - 17:00<BR>
Profesores: Pepa Hern√°ndez (phernan@fi.upm.es), Nik Swoboda (nswoboda@fi.upm.es), Javier Bajo (jbajo@fi.upm.es). <BR>
Dpto. de Inteligencia Artificial, despacho 2205<BR>
Tf.: 91 336 6901<BR>


# Course Project Proposals
Below you will find three suggestions for the course project. Each suggestion is divided into two parts, a "core" system to implement and then a list of open-ended extensions.  Students who follow these suggestions should at least implement one of the core systems. We also would like to encourage you to do some "real" researc while working on this project by pursuing one or more of the extensions. Thus, while grading the projects we will take the following into consideration:

* The level of sophistication or complexity of the implemented system.
* The existence and significance of an individual contribution to the project.  I.e., we are particularly interested in seeing original improvements, extensions, evaluations, and criticisms as part of both the implemented system and the written report.

As we mentioned in class, this list is intended to help you get started thinking about the project. Students are welcome to work on other collective intelligence related projects not mentioned below. But in such cases we highly recommend that you discuss your ideas with either Pepa or Nik to get some feedback.


1) Parameter optimization for the Travelling Salesman Problem

The Travelling Salesman Problem (ISP) is popular NP-Hard problem for testing combinatorial optimization algorithms.  Of the techniques seen this semester, the ACO family of algorithms are probably the most natural match to the problem, but PSO and many other approaches can be applied.

Core: Select a somewhat complicated instance of the TSP problem from a test data repository (for example link or link) and experiment with one of the algorithms we have seen this semester to solve that instance.  Report on the parameters used and their impact on the performance of the algorithm.

Extensions:

Parameter optimization is a key component of any successful application of collective intelligence techniques.  Investigate and apply some intelligent technique to optimize the parameters used by the algorithm to solve one specific problem (for example to find the optimal solution to some particular instance) and report upon the results.
Implement a number of different algorithms (for example some subset of PSO, ACO, GA, Dynamic Programming ...) and report on the performance comparisons of the different techniques.


